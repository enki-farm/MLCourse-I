{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c01dcf",
   "metadata": {},
   "source": [
    "# üß† NLP 102 ‚Äì Word Embeddings & Visualizing Meaning\n",
    "\n",
    "## Featuring The Hitchhiker‚Äôs Guide to the Galaxy\n",
    "### ‚è±Ô∏è Duration: ~30 minutes\n",
    "### üõ†Ô∏è Requirements: Python 3, Jupyter Notebook or any Python IDE, nltk, gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d63b881-258a-46a7-a46a-80bc994e208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: FOR COLAB INSTALL DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e49bdc3-d43b-45b2-bc80-e72b5441fdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "anyio                     4.9.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.5\n",
      "attrs                     25.3.0\n",
      "babel                     2.17.0\n",
      "beautifulsoup4            4.13.3\n",
      "bleach                    6.2.0\n",
      "certifi                   2025.1.31\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.1\n",
      "click                     8.1.8\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.0\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.13\n",
      "decorator                 5.2.1\n",
      "defusedxml                0.7.1\n",
      "exceptiongroup            1.2.2\n",
      "executing                 2.2.0\n",
      "fastjsonschema            2.21.1\n",
      "fonttools                 4.57.0\n",
      "fqdn                      1.5.1\n",
      "gensim                    4.3.3\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.28.1\n",
      "idna                      3.10\n",
      "importlib_metadata        8.6.1\n",
      "importlib_resources       6.5.2\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.18.1\n",
      "ipywidgets                8.1.5\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.6\n",
      "joblib                    1.4.2\n",
      "json5                     0.12.0\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.4.0\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "kiwisolver                1.4.7\n",
      "llvmlite                  0.43.0\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib                3.9.4\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.1.3\n",
      "narwhals                  1.34.0\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "nltk                      3.9.1\n",
      "nnfs                      0.5.1\n",
      "notebook_shim             0.2.4\n",
      "numba                     0.60.0\n",
      "numpy                     1.26.4\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pillow                    11.1.0\n",
      "pip                       23.0.1\n",
      "platformdirs              4.3.7\n",
      "plotly                    6.0.1\n",
      "prometheus_client         0.21.1\n",
      "prompt_toolkit            3.0.50\n",
      "psutil                    7.0.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pycparser                 2.22\n",
      "Pygments                  2.19.1\n",
      "pynndescent               0.5.13\n",
      "pyparsing                 3.2.3\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        3.3.0\n",
      "pytz                      2025.2\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.4.0\n",
      "referencing               0.36.2\n",
      "regex                     2024.11.6\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.24.0\n",
      "scikit-learn              1.6.1\n",
      "scipy                     1.13.1\n",
      "seaborn                   0.13.2\n",
      "Send2Trash                1.8.3\n",
      "setuptools                58.1.0\n",
      "six                       1.17.0\n",
      "smart-open                7.1.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "terminado                 0.18.1\n",
      "threadpoolctl             3.6.0\n",
      "tinycss2                  1.4.0\n",
      "tomli                     2.2.1\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.13.1\n",
      "tzdata                    2025.2\n",
      "umap-learn                0.5.7\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.45.1\n",
      "widgetsnbextension        4.0.13\n",
      "wordcloud                 1.9.4\n",
      "wrapt                     1.17.2\n",
      "zipp                      3.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba0057",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Overview\n",
    "\n",
    "Traditional methods like Bag-of-Words or TF-IDF ignore word meaning and context. That‚Äôs where embeddings shine.\n",
    "Embeddings represent words as dense vectors in a multi-dimensional space where semantic similarity = spatial closeness.\n",
    "\n",
    "In this notebook, you will:\n",
    "- Understand what word embeddings are and why they are powerful\n",
    "- Learn how to train a simple Word2Vec model using gensim\n",
    "- Use UMAP to reduce the dimensionality of word vectors\n",
    "- Create an interactive plot to explore word relationships visually\n",
    "\n",
    "üß© By the end, you'll be able to see how similar words cluster together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a2cd3",
   "metadata": {},
   "source": [
    "## üì¶ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f1583-76fb-4eea-9bd1-b7c118f95bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Time is an illusion. Lunchtime doubly so.\",\n",
    "    \"The ships hung in the sky in much the same way that bricks don‚Äôt.\",\n",
    "    \"The Hitchhiker‚Äôs Guide to the Galaxy is a wholly remarkable book.\",\n",
    "    \"The Answer to the Great Question... of Life, the Universe and Everything... is... Forty-two.\",\n",
    "    \"Don‚Äôt Panic.\",\n",
    "    \"So long, and thanks for all the fish.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dab795",
   "metadata": {},
   "source": [
    "## üß™ Exercise 0: Prepare your data\n",
    "\n",
    "**Goal:** Tokenize the corpus\n",
    "\n",
    "**Optional:** Load the whole book from disk and use it as corpus\n",
    "###¬†üß∞ Tools:\n",
    "\n",
    "`word_tokenize` from `nltk.tokenize`\n",
    "\n",
    "`simple_preprocess` from `gensim.utils`\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Preprocess the data\n",
    "- Create a corpus\n",
    "- Optional: Load book from disk\n",
    "- Optional: Split sentences\n",
    "- Optional: Create corpus from whole book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b998d61-8a3e-46ce-9fba-c37b68bade66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c25b8-5643-4db9-8fc0-8822a52e2879",
   "metadata": {},
   "source": [
    "## üß™ Exercise 1: Create Model and explore word similarities\n",
    "\n",
    "**Goal:** Train a Word2Vec Model \n",
    "\n",
    "**Optional:** Explore different parameters\n",
    "\n",
    "**Super Optional:** Test a word not in the vocabulary\n",
    "\n",
    "###¬†üß∞ Tools:\n",
    "\n",
    "`Word2Vec` from `gensim.models`\n",
    "\n",
    "`wv.most_similar` from your trained model\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Create an instance of `Word2Vec`\n",
    "- Use the tokenized corpus as data\n",
    "- Test some word similarities\n",
    "- Optional: Make one with `skip-gram` and one with `CBOW`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcddb9f8-0093-4456-a444-1004ecd3b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6436b3",
   "metadata": {},
   "source": [
    "## üß™ Exercise 2: Visualize with UMAP\n",
    "\n",
    "**UMAP (Uniform Manifold Approximation and Projection)** is a dimensionality reduction technique that preserves both local and global structure in data, making it great for visualizing high-dimensional embeddings. It works by modeling the data as a graph and optimizing a low-dimensional representation that maintains the original relationships as closely as possible.\n",
    "\n",
    "**Goal:** Reduce the word2vec vectors to two dimensions and visualize them.\n",
    "\n",
    "**Optional:** Use t-SNE as alternative\n",
    "\n",
    "**Super Optional:** Experiment with different parameters\n",
    "\n",
    "###¬†üß∞ Tools:\n",
    "\n",
    "`UMAP` from `umap`\n",
    "\n",
    "`array` from `numpy`\n",
    "\n",
    "Optional: `TSNE` from `sklearn.manifold`\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Extract all words and vectors\n",
    "- Reduce dimensions\n",
    "- Plot the result\n",
    "\n",
    "###¬†‚úÖ Expected Output (example):\n",
    "\n",
    "Plot of the reduced word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc5c91-4cf2-40fd-852b-bd3fa761ec51",
   "metadata": {},
   "source": [
    "## üß™ Exercise 3: Interactive plot with plotly\n",
    "\n",
    "**Goal:** Create a plot where you can interactively explore the UMAP data\n",
    "\n",
    "###¬†üß∞ Tools:\n",
    "\n",
    "`scatter` from `plotly`\n",
    "\n",
    "`dataframe` from `pandas`\n",
    "\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Prepare a dataframe\n",
    "- Make an interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb89f8-a45d-41f0-8e70-08cd38fb19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7a842-8cc2-4b16-bef6-8690640aebf2",
   "metadata": {},
   "source": [
    "## üß™ Exercise 4: Use pre-trained Word2Vec\n",
    "\n",
    "**Goal:** Load a pre-trained Word2Vec model and explore what is different\n",
    "\n",
    "**Optional:** Load two pre-trained Word2Vec models and explore how they differ\n",
    "\n",
    "**Super Optional:** Visualize some word from a pretrained Word2Vec model\n",
    "\n",
    "**Super Super Optiona:** Visualize some words from two pretrained models in the same plot\n",
    "\n",
    "###¬†üß∞ Tools:\n",
    "\n",
    "`load` from `gensim.downloader`\n",
    "\n",
    "`info` from `gensim.downloader` (Use this to list available models)\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Load a pretrained model\n",
    "- Create a list of words you want to test\n",
    "- Calculate the 3 most similar\n",
    "\n",
    "###¬†‚úÖ Expected Output (example):\n",
    "\n",
    "```python\n",
    "üîé Word: computer\n",
    "3 most similar: [('computers', 0.916504442691803), ('software', 0.8814992904663086), ('technology', 0.852556049823761)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6824223-e923-4b87-a15d-78cbd05e7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
