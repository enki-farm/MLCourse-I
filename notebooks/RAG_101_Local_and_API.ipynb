{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781b8f32",
   "metadata": {},
   "source": [
    "# üß± Modular RAG Pipeline\n",
    "This notebook walks you through building a modular Retrieval-Augmented Generation (RAG) pipeline using:\n",
    "- `docling` for document parsing\n",
    "- `lancedb` for vector search\n",
    "- `OpenAI` for answering queries with retrieved context\n",
    "\n",
    "Each step is wrapped in functions for clean and reusable design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c28dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docling lancedb openai pandas requests tqdm python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ceebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O .env https://farmsilo.blob.core.windows.net/mlcourse/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd7998-b24e-4264-9bdb-e9e4faa18973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365726d-bac3-4948-be0c-1cf22da3c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "pipeline_options.do_table_structure = True\n",
    "pipeline_options.table_structure_options.do_cell_matching = True\n",
    "pipeline_options.ocr_options.lang = [\"en\"]\n",
    "\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "def parse_document(file_path):\n",
    "    print(\"üìÑ Loading and parsing document...\")\n",
    "    result = doc_converter.convert(source=file_path)\n",
    "    \n",
    "    if len(result.errors) > 0:\n",
    "        print(f\"‚ùå Conversion has {len(result.errors)} errors\")\n",
    "    \n",
    "    print(f\"‚úÖ Parsed {len(result.pages)} pages.\")\n",
    "    print(\"----------------------------------\\n\")\n",
    "    return result.document.export_to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1504e5-3ea5-4e67-810c-541df46d5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab: Upload data\n",
    "doc = parse_document(\"data/bitcoin.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688d349-baa8-472a-876d-7b7f6a455fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 100):\n",
    "    \"\"\"\n",
    "    Naively splits a markdown string into fixed-size chunks with optional overlap.\n",
    "\n",
    "    Args:\n",
    "        text (str): The markdown string to split.\n",
    "        max_length (int): Maximum number of characters per chunk.\n",
    "        overlap (int): Number of overlapping characters between chunks.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of text chunks.\n",
    "    \"\"\"\n",
    "    print(\"‚úÇÔ∏è Chunking document with overlap...\")\n",
    "    \n",
    "    if chunk_size <= overlap:\n",
    "        raise ValueError(\"max_length must be greater than overlap\")\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap\n",
    "\n",
    "    print(f\"‚úÖ Created {len(chunks)} chunks of size {chunk_size} with overlap {overlap}. First chunk preview:\\n{chunks[0][:min(200, chunk_size)]}...\")\n",
    "    print(\"----------------------------------\\n\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942aeafa-4893-4606-9d2e-249517e55978",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(doc, chunk_size=500, overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a991a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "EMBEDDER_URL = \"https://embedserver.enki.farm/v2/models/embed/infer\"\n",
    "EMBEDDER_API_KEY = os.getenv(\"ENKI_API_KEY\")\n",
    "\n",
    "headers = {\n",
    "    \"X-ENKI-FARM-API-KEY\": EMBEDDER_API_KEY\n",
    "}\n",
    "\n",
    "def embedd_chunk(chunk):\n",
    "    inference_request = {\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": \"text_chunk\",\n",
    "                \"shape\": [1],\n",
    "                \"datatype\": \"BYTES\",\n",
    "                \"data\": [chunk]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(EMBEDDER_URL, json=inference_request, headers=headers)\n",
    "        result = response.json()\n",
    "        return result[\"outputs\"][0][\"data\"]\n",
    "    except Exception as ex:\n",
    "        print(f\"Error: {ex}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def get_embeddings(chunks):\n",
    "    print(f\"üß† Generating embeddings for {len(chunks)} chunks...\")\n",
    "    embeddings = []\n",
    "\n",
    "    for chunk in tqdm(chunks):\n",
    "        embedding = embedd_chunk(chunk)\n",
    "\n",
    "        if embedding:\n",
    "            embeddings.append(embedding)\n",
    "    \n",
    "    print(f\"‚úÖ Generated {len(embeddings)} embeddings. Vector size: {len(embeddings[0])}\")\n",
    "    print(\"----------------------------------\\n\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3648230-235b-4c78-b4ee-3adb485e49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d551a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "import pandas as pd\n",
    "\n",
    "def create_lancedb_table(db_path: str, texts, embeddings, table_name=\"documents\"):\n",
    "    print(\"üì¶ Creating LanceDB table...\")\n",
    "    db = lancedb.connect(db_path)\n",
    "    df = pd.DataFrame({\n",
    "        \"text\": texts,\n",
    "        \"vector\": embeddings\n",
    "    })\n",
    "    table = db.create_table(table_name, data=df, mode=\"overwrite\")\n",
    "    print(f\"‚úÖ Stored {len(texts)} records in '{table_name}' table.\")\n",
    "    print(\"----------------------------------\\n\")\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5357924-a53e-4a20-82d2-c5fe4627a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_table = create_lancedb_table(\"./bitcoin-embs\", chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, table, top_k=1):\n",
    "    print(f\"üîç Retrieving top {top_k} chunks for query: '{query}'\")\n",
    "    query_embedding = get_embeddings(172[query])[0]\n",
    "    results = table.search(query_embedding).limit(top_k).to_pandas()\n",
    "    context = \"\\n\".join(results[\"text\"])\n",
    "    print(f\"‚úÖ Retrieved context:\\n{context[:500]}...\\n\")\n",
    "    print(\"----------------------------------\\n\")\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fef40-460b-4a16-a259-3fa4cce8b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What can the public see about bitcoin transactions?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd390aa-560a-4fb0-aecd-21f56219fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = retrieve_context(query, document_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae63a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "LLM_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=LLM_API_KEY,\n",
    ")\n",
    "\n",
    "def generate_answer(query, context, model=\"gpt-4o-mini\"):\n",
    "    print(\"ü§ñ Generating answer using LLM...\")\n",
    " \n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        instructions=\"You are a helpful assistant. Use the following context to answer the question.\",\n",
    "        input=f\"\"\"\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question:\n",
    "        {query}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    answer = response.output_text\n",
    "    print(f\"‚úÖ Answer generated:\\n{answer}\")\n",
    "    print(\"----------------------------------\\n\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02adb7b-0868-47dd-80e3-81848673345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = generate_answer(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_pipeline(\n",
    "    file_path,\n",
    "    query,\n",
    "    db_path=\"./rag-db\",\n",
    "    table_name=\"documents\",\n",
    "    top_k=1,\n",
    "    chunk_size=500,\n",
    "    overlap=100\n",
    "):\n",
    "    doc = parse_document(file_path)\n",
    "    chunks = chunk_text(doc, chunk_size=chunk_size, overlap=overlap)\n",
    "    embeddings = get_embeddings(chunks)\n",
    "    table = create_lancedb_table(db_path, chunks, embeddings, table_name)\n",
    "    context = retrieve_context(query, table, top_k=top_k)\n",
    "    answer = generate_answer(query, context)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Example Usage\n",
    "run_rag_pipeline(\n",
    "    file_path=\"data/bitcoin.pdf\",\n",
    "    query=\"What can the public see about bitcoin transactions?\",\n",
    "    chunk_size=500,\n",
    "    overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d5b83-f95e-4211-b931-7cd9c20e7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"bitcoin-embs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c789bd7-2a35-436c-be84-28f7c90427c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
