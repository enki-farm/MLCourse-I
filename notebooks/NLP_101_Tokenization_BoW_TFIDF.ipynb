{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c01dcf",
   "metadata": {},
   "source": [
    "# üß† NLP 101 for Programmers\n",
    "\n",
    "## Featuring The Hitchhiker‚Äôs Guide to the Galaxy\n",
    "### ‚è±Ô∏è Duration: ~30 minutes\n",
    "### üõ†Ô∏è Requirements: Python 3, Jupyter Notebook or any Python IDE, nltk, scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba0057",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Overview\n",
    "\n",
    "Welcome to your first dive into NLP! In this tutorial, we‚Äôll explore how machines process and understand text. We‚Äôll start with:\n",
    "- Tokenization ‚Äì breaking down text into individual units\n",
    "- Bag of Words (BoW) ‚Äì a simple representation of text\n",
    "- TF-IDF ‚Äì identifying important words in context\n",
    "\n",
    "You'll work on short excerpts from The Hitchhiker‚Äôs Guide to the Galaxy and complete three exercises along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a2cd3",
   "metadata": {},
   "source": [
    "## üì¶ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4041ec87",
   "metadata": {},
   "source": [
    "## üß™ Exercise 1: Tokenization\n",
    "\n",
    "**Goal:** Break a passage into tokens and print english stopwords\n",
    "\n",
    "**Optional:** Preprocess it to remove punctuation, numbers and stopwords\n",
    "\n",
    "**Super Optional:** Visualize the result with a bar plot\n",
    "\n",
    "### üìñ Sample Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e080929",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Far out in the uncharted backwaters of the unfashionable end of the western spiral arm of the Galaxy lies \n",
    "a small unregarded yellow sun.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dab795",
   "metadata": {},
   "source": [
    "###¬†üß∞ Tools:\n",
    "\n",
    "`word_tokenize` from `nltk.tokenize`\n",
    "\n",
    "`Counter` from `collections`\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Print english stopwords.\n",
    "- Tokenize the above text.\n",
    "- Count the number of unique tokens.\n",
    "- Print the top 5 most frequent tokens.\n",
    "\n",
    "###¬†‚úÖ Expected Output (example):\n",
    "\n",
    "```python\n",
    "Tokens: ['Far', 'out', 'in', 'the', 'uncharted', 'backwaters', ...]\n",
    "Unique tokens: 19\n",
    "Most frequent: [('the', 3), ('of', 2), ('Far', 1), ...]\n",
    "\n",
    "{'to', \"don't\", 'd', 'having'...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b998d61-8a3e-46ce-9fba-c37b68bade66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1680132",
   "metadata": {},
   "source": [
    "## üß™ Exercise 2: Bag of Words\n",
    "\n",
    "**Goal:** Represent text as a word-count vector\n",
    "\n",
    "**Optional:** Visualize the result with a heatmap\n",
    "\n",
    "### üìñ Sample Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526a2f4-6eb3-44e8-a395-597b7ecdc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"The ships hung in the sky in much the same way that bricks don‚Äôt.\",\n",
    "    \"Time is an illusion. Lunchtime doubly so.\",\n",
    "    \"The Answer to the Great Question... Of Life, the Universe and Everything... Is... Forty-two.\",\n",
    "    \"It was a  particular  type  of  rain  he  particularly  disliked, particularly  when he was driving. He had a number for it. It was rain type 17.\",\n",
    "    \"He blinked, and understood nothing.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c25b8-5643-4db9-8fc0-8822a52e2879",
   "metadata": {},
   "source": [
    "###¬†üß∞ Tools:\n",
    "\n",
    "`CountVectorizer` from `sklearn.feature_extraction.text`\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Convert the 5 texts into a Bag of Words representation.\n",
    "- Print the vocabulary.\n",
    "- Print the count matrix as a DataFrame for readability.\n",
    "\n",
    "###¬†‚úÖ Expected Output (example):\n",
    "\n",
    "```python\n",
    "Vocabulary: ['answer', 'bricks', 'don‚Äôt', 'everything', ...]\n",
    "BoW Matrix:\n",
    "|        | answer | bricks | don‚Äôt | everything | ... |\n",
    "|--------|--------|--------|-------|------------|-----|\n",
    "| Text 1 | 0      | 1      | 1     | 0          | ... |\n",
    "| Text 2 | 0      | 0      | 0     | 0          | ... |\n",
    "| Text 3 | 1      | 0      | 0     | 1          | ... |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcddb9f8-0093-4456-a444-1004ecd3b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6436b3",
   "metadata": {},
   "source": [
    "## üß™ Exercise 3: TF-IDF\n",
    "\n",
    "**Goal:** Identify the most meaningful words in each sentence\n",
    "\n",
    "###¬†üß∞ Tools:\n",
    "\n",
    "`TfidfVectorizer` from `sklearn.feature_extraction.text`\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Convert the same texts into TF-IDF vectors.\n",
    "- Print the resulting matrix as a DataFrame.\n",
    "- Highlight the top 3 words with the highest TF-IDF scores per text.\n",
    "\n",
    "###¬†‚úÖ Expected Output (example):\n",
    "\n",
    "```python\n",
    "TF-IDF Matrix:\n",
    "|        | answer | bricks | don‚Äôt | everything | ... |\n",
    "|--------|--------|--------|-------|------------|-----|\n",
    "| Text 1 | 0.0    | 0.707  | 0.707 | 0.0        | ... |\n",
    "| Text 2 | 0.0    | 0.0    | 0.0   | 0.0        | ... |\n",
    "| Text 3 | 0.5    | 0.0    | 0.0   | 0.5        | ... |\n",
    "\n",
    "Top words:\n",
    "- Text 1: bricks, don‚Äôt, sky\n",
    "- Text 2: illusion, lunchtime, doubly\n",
    "- Text 3: answer, everything, universe\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795fc1a2-f9b6-4811-90b4-0bbca8126b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cada0c5-0545-43c1-9c64-c152c093ff1a",
   "metadata": {},
   "source": [
    "## üß™ Exercise 4: Word-Level Distance Comparisons\n",
    "\n",
    "**Goal:** Explore how close or far apart individual words are based on the vector space created during tokenization.\n",
    "\n",
    "**Optional:** Implement a simple k-Nearest Neighbours\n",
    "\n",
    "###¬†üß∞ Tools:\n",
    "\n",
    "`cosine_similarity` (or any other) from `sklearn.metrics.pairwise`\n",
    "\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Select two words from the dictionary\n",
    "- Calculate the distance between them\n",
    "- Optional: Pick a word and calculate all distances to the other words (order them ascending) - print k\n",
    "\n",
    "###¬†‚úÖ Expected Output (example):\n",
    "\n",
    "```python\n",
    "Word 1 has distance 0.457234 to Word 2\n",
    "\n",
    "# optional\n",
    "The 3 nearest words to word 1 are:\n",
    "Word 2: 0.0123\n",
    "Word 7: 0.1543\n",
    "Word 4: 0.2872\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc5c91-4cf2-40fd-852b-bd3fa761ec51",
   "metadata": {},
   "source": [
    "## üß™ Exercise 5: Cosine Similarity Between Texts\n",
    "\n",
    "**Goal:** Find which texts are most similar using vector math\n",
    "\n",
    "**Optional:** Test different Metrics (checkout `sklearn.metrics.pairwise`)\n",
    "\n",
    "**Super Optional:** Compare with preprocessed texts\n",
    "\n",
    "###¬†üß∞ Tools:\n",
    "\n",
    "`cosine_similarity` from `sklearn.metrics.pairwise`\n",
    "\n",
    "`heatmap` from `seaborn`\n",
    "\n",
    "###¬†üíª Task:\n",
    "- Calculate the Cosine Similarity between all vectors\n",
    "- Print the resulting matrix as a DataFrame.\n",
    "- Create a heatmap to visualize the most similar texts\n",
    "\n",
    "###¬†‚úÖ Expected Output (example):\n",
    "\n",
    "Heatmap plot of doc simillarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb89f8-a45d-41f0-8e70-08cd38fb19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4fc1a-e3bb-4bae-a87c-865001e9dbac",
   "metadata": {},
   "source": [
    "## üß™ Exercise 6: Full Book Analysis ‚Äì Frequency & Cosine Similarity\n",
    "\n",
    "**Goal:** Dive into the full text of *The Hitchhiker‚Äôs Guide to the Galaxy* to find the most frequent words and analyze text similarity.\n",
    "\n",
    "**Optional:** Calculate the distances from exercise 4 again.\n",
    "\n",
    "\n",
    "### üß∞ Tools:\n",
    "\n",
    "`CountVectorizer`, `TfidfVectorizer` from `sklearn.feature_extraction.text`  \n",
    "\n",
    "`cosine_similarity` from `sklearn.metrics.pairwise`  \n",
    "\n",
    "`seaborn.heatmap`  \n",
    "\n",
    "\n",
    "### üíª Task:\n",
    "\n",
    "- Load the full text of *The Hitchhiker‚Äôs Guide to the Galaxy*.\n",
    "- Split the book into segments (e.g. paragraphs or chunks of N sentences).\n",
    "- Vectorize the segments using TF-IDF.\n",
    "- Compute the cosine similarity between all segments.\n",
    "- Create a heatmap showing segment similarity.\n",
    "- List the top 20 most frequent words in the book.\n",
    "- Calculate the distance again.\n",
    "\n",
    "\n",
    "### ‚úÖ Expected Output (example):\n",
    "\n",
    "- A heatmap showing which parts of the book are most similar  \n",
    "- A DataFrame of cosine similarity values  \n",
    "- A printed list of the top 20 most frequent words  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f996263-4055-4f6b-a936-fe1498a5c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
